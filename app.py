import io
import os
from flask import Flask, request, jsonify, render_template, g, send_file
import pandas as pd
import requests
from rag_db import RAGDatabase
from prometheus_flask_exporter import PrometheusMetrics
from prometheus_client import Histogram
import time
import json
import re
from monitoring import *

#testing mail
# –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é JSON-based —Å–∏—Å—Ç–µ–º—É —à–∞–±–ª–æ–Ω–æ–≤ (v2.0)
from letters_templates_v2 import template_manager

app = Flask(__name__)
app.secret_key = os.environ.get("FLASK_SECRET_KEY", "dev-unsafe-secret-key-change-me")
MODEL_API_URL = "http://localhost:5050/generate"

# Prometheus
CUSTOM_BUCKETS = [5, 10, 20, 30, 40, 50, 60]
metrics = PrometheusMetrics(app)
metrics.info("app_info", "O2 Copilot Flask App", version="1.0.0")

REQUEST_DURATION = Histogram(
    "http_request_duration_seconds",
    "Request duration in seconds (custom buckets, only /api/messages)",
    ["method", "path"],
    buckets=CUSTOM_BUCKETS,
)


@app.teardown_appcontext
def close_db(exception):
    db = g.pop("db", None)
    if db is not None:
        db.close()


@app.before_request
def before_request():
    request.start_time = time.time()
    if request.path.startswith("/api"):
        get_or_create_session_id()


@app.after_request
def after_request(response):
    if hasattr(request, "start_time"):
        duration = time.time() - request.start_time
        try:
            REQUEST_DURATION.labels(method=request.method, path=request.path).observe(
                duration
            )
        except ValueError as e:
            app.logger.error(f"Prometheus labeling error: {e}")
    return response


@app.route("/")
def index():
    return render_template("index.html")


@app.route("/api/messages", methods=["POST"])
def messages():
    sid = get_or_create_session_id()
    data = request.get_json()
    if not data or "text" not in data:
        return jsonify({"error": "Invalid input"}), 400

    user_message = data["text"]
    db = get_db()
    db.execute(
        """
        INSERT INTO messages (session_id, timestamp, query_text)
        VALUES (?, ?, ?)
        """,
        (sid, datetime.now(tz=timezone(timedelta(hours=3))), user_message),
    )
    db.commit()

    selected_datasets = data.get("datasets", [])
    mode = data["mode"]
    print(
        f"–ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ: {user_message}\n–í—ã–±—Ä–∞–Ω–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã: {selected_datasets}."
    )

    try:
        # –ü–æ–∏—Å–∫ –≤ RAG-–±–∞–∑–µ
        relevant_docs, user_message = rag_db.search(
            user_message, selected_datasets=selected_datasets, final_k=3, initial_k=25
        )
        print("–î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–∞—à–ª–∏—Å—å!")
        context = "\n\n".join(
            f"Metadata: {doc['metadata'].split('/')[-1]}\nData: {doc['chunk']}"
            for doc in relevant_docs
        )

        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
        system_content = (
            "–¢—ã ‚Äî –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ò–≥–æ—Ä—å –ò–≤–∞–Ω–æ–≤–∏—á –¥–ª—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –∫–æ–º–ø–∞–Ω–∏–∏ Nestle. –û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ HTML –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞. –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–∏—á–µ–≥–æ –æ—Ç —Å–µ–±—è.\n"
            "=== –ü–û–í–ï–î–ï–ù–ß–ï–°–ö–ò–ï –ü–†–ê–í–ò–õ–ê ===\n"
            "1. –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî –Ω–∞—á–Ω–∏ —Å: '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ [–æ–±—ä–µ–∫—Ç] –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –û–¥–Ω–∞–∫–æ –µ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ...'\n"
            "2. –ß—ë—Ç–∫–æ —Ä–∞–∑–¥–µ–ª—è–π —Å—É—â–Ω–æ—Å—Ç–∏: –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª–∏ ‚â† –∫–ª–∏–µ–Ω—Ç—ã, –∫–ª–∏–µ–Ω—Ç—ã ‚â† –ø–æ—Å—Ç–∞–≤—â–∏–∫–∏, –∫–æ—Ñ–µ ‚â† –¥–µ—Ç—Å–∫–æ–µ –ø–∏—Ç–∞–Ω–∏–µ –∏ —Ç.–¥.\n"
            "3. –°—Ç–∞—Ä–∞–π—Å—è –¥–∞–≤–∞—Ç—å –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç.\n"
            "4. –ü—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π –≤ –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö ‚Äî –ø–µ—Ä–µ—á–∏—Å–ª–∏ –í–°–ï –≤–∞—Ä–∏–∞–Ω—Ç—ã.\n"
            "5. –ö–∞–∂–¥—ã–π —Å–º—ã—Å–ª–æ–≤–æ–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –æ—Ç–≤–µ—Ç–∞ —Å–æ–ø—Ä–æ–≤–æ–∂–¥–∞–π —Å—Å—ã–ª–∫–æ–π –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫ –≤ —Ñ–æ—Ä–º–∞—Ç–µ [1], [2], ...\n"
            "6. –í –∫–æ–Ω—Ü–µ –æ—Ü–µ–Ω–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ 10-–±–∞–ª–ª—å–Ω–æ–π —à–∫–∞–ª–µ (0 -- –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–∏–∫–∞–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å, 10 -- –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å –≤—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å)\n\n"
            "=== –§–û–†–ú–ê–¢ HTML ===\n"
            "1. <h3> ‚Äî –∑–∞–≥–æ–ª–æ–≤–∫–∏\n"
            "2. <b>, <i> ‚Äî –≤—ã–¥–µ–ª–µ–Ω–∏–µ\n"
            "3. <ol>/<ul> ‚Äî —Å–ø–∏—Å–∫–∏\n"
            "4. –ü–æ—Å–ª–µ –¥–≤–æ–µ—Ç–æ—á–∏–π ‚Äî —Å—Ç—Ä–æ—á–Ω–∞—è –±—É–∫–≤–∞\n\n"
            "=== –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–ê–Ø –°–¢–†–£–ö–¢–£–†–ê –û–¢–í–ï–¢–ê ===\n"
            "1. –û—Å–Ω–æ–≤–Ω–æ–π –æ—Ç–≤–µ—Ç\n"
            "2. –ò—Å—Ç–æ—á–Ω–∏–∫–∏ —Å–æ —Å–ø–∏—Å–∫–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–∏—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ —Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, –ø–µ—Ä–µ–¥ –∫–æ—Ç–æ—Ä—ã–º–∏ –µ—Å—Ç—å 'Metadata:')\n\n"
            "=== –ü–†–ò–ú–ï–† –ü–†–ê–í–ò–õ–¨–ù–û–ì–û –û–¢–í–ï–¢–ê ===\n\n"
            "<h3>–†–µ—à–µ–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–∞</h3>\n"
            "<p>–î–ª—è —Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º—ã –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å —Å–ª–µ–¥—É—é—â–∏–µ –¥–µ–π—Å—Ç–≤–∏—è:</p>\n"
            "<ol>\n"
            "  <li>–ü–µ—Ä–≤–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ [1]</li>\n"
            "  <li>–í—Ç–æ—Ä–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ [2]</li>\n"
            "</ol>\n"
            "<h3>–ò—Å—Ç–æ—á–Ω–∏–∫–∏</h3>\n"
            "<ol>\n"
            "  <li>1.docx</li>\n"
            "  <li>2.pdf</li>\n"
            "</ol>\n"
            "<p style='text-align: right;'><i>–¢–æ—á–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞:<b> x/10</b></i></p>\n\n"
        )

        if mode == "letter":
            print(f"\nüìß –†–µ–∂–∏–º –ø–∏—Å—å–º–∞ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω")
            print(f"–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_message[:100]}...")
            
            # ===== –ü–û–õ–£–ß–ê–ï–ú actual_docs –∏ links_dict –ó–ê–†–ê–ù–ï–ï =====
            try:
                with open("links.json", "r", encoding="utf-8") as f:
                    links_dict = json.load(f)
            except (FileNotFoundError, json.JSONDecodeError):
                links_dict = {}
            
            actual_docs = [
                doc["metadata"].split("docs_Samara/")[1] for doc in relevant_docs
            ]
            
            # ===== –ü–û–ò–°–ö –®–ê–ë–õ–û–ù–ê =====
            template_config = template_manager.find_matching_template(
                query=user_message,
                error_message=context
            )
            
            if template_config:
                # ‚úÖ –®–∞–±–ª–æ–Ω –Ω–∞–π–¥–µ–Ω - –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
                print(f"‚úâÔ∏è –ù–∞–π–¥–µ–Ω —à–∞–±–ª–æ–Ω: {template_config['description']}")
                print(f"‚öôÔ∏è –î–µ–π—Å—Ç–≤–∏–µ: {template_config['action']}")
                print(f"üìÑ MSG —Ñ–∞–π–ª: {template_config.get('msg_filename', '–Ω–µ—Ç')}")
                
                response_data = template_manager.prepare_letter_response(
                    template_config=template_config,
                    user_context=user_message
                )
                
                if response_data:
                    # –§–æ—Ä–º–∏—Ä—É–µ–º mailto –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–Ω–æ–ø–∫–∏
                    mailto_data = {
                        "to": response_data.get("to", "Customer.Service@nestle.ru"),
                        "cc": response_data.get("cc", ""),
                        "subject": response_data.get("subject", ""),
                        "body": response_data.get("response", "")
                    }
                    
                    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —à–∞–±–ª–æ–Ω–µ
                    action = template_config['action']
                    action_text = template_config.get('action_text', '')
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –¥–µ–π—Å—Ç–≤–∏–∏
                    action_info = ""
                    if action == 'block_and_notify':
                        action_info = "<p><strong>‚ö†Ô∏è –î–ï–ô–°–¢–í–ò–ï:</strong> –ë–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å IDoc –∏ –æ–ø–æ–≤–µ—Å—Ç–∏—Ç—å CSA</p>"
                    elif action == 'block_no_notify':
                        action_info = "<p><strong>‚ö†Ô∏è –î–ï–ô–°–¢–í–ò–ï:</strong> –ë–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å IDoc –ë–ï–ó –æ–ø–æ–≤–µ—â–µ–Ω–∏—è CSA</p>"
                    elif action == 'push_and_notify':
                        action_info = "<p><strong>‚úÖ –î–ï–ô–°–¢–í–ò–ï:</strong> –ü—Ä–æ—Ç–æ–ª–∫–Ω—É—Ç—å IDoc –∏ –æ–ø–æ–≤–µ—Å—Ç–∏—Ç—å</p>"
                    elif action == 'lenta_gln_change':
                        action_info = "<p><strong>üè™ –î–ï–ô–°–¢–í–ò–ï:</strong> –ó–∞–º–µ–Ω–∞ GLN –¥–ª—è –õ–µ–Ω—Ç—ã</p>"
                    
                    # –§–æ—Ä–º–∏—Ä—É–µ–º HTML –æ—Ç–≤–µ—Ç
                    response_text = f"""<h3>–†–µ—à–µ–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–æ</h3>
        <p><strong>–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —à–∞–±–ª–æ–Ω:</strong> {template_config['description']}</p>
        {action_info}
        <hr>
        <h4>–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:</h4>
        <div style="white-space: pre-wrap;">{action_text}</div>"""
                    
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
                    processed_response = process_sources(response_text, actual_docs, links_dict)
                    
                    return jsonify({
                        "type": "message",
                        "text": processed_response,
                        "mailto": mailto_data
                    })
            
            # ===== FALLBACK: AI –ì–ï–ù–ï–†–ê–¶–ò–Ø =====
            print("ü§ñ –®–∞–±–ª–æ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–∏—Å—å–º–æ —á–µ—Ä–µ–∑ AI...")
            
            system_content += (
                "\n\n=== –†–ï–ñ–ò–ú –ù–ê–ü–ò–°–ê–ù–ò–Ø –ü–ò–°–¨–ú–ê ===\n"
                "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ö–æ—á–µ—Ç, —á—Ç–æ–±—ã —Ç—ã —Å–æ—Å—Ç–∞–≤–∏–ª –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–µ –ø–∏—Å—å–º–æ.\n"
                "–í –∫–æ–Ω—Ü–µ –æ—Ç–≤–µ—Ç–∞ –¥–æ–±–∞–≤—å JSON-–±–ª–æ–∫. –ù–∞–ø—Ä–∏–º–µ—Ä, —Ç–∞–∫–æ–π:\n"
                "```json\n"
                "{\n"
                '  "mailto": {\n'
                '    "to": "customer.distributors@nestle.ru, Customer.Service@nestle.ru",\n'
                '    "cc": "Orders@nestle.ru",\n'
                '    "subject": "–¢–µ–º–∞ –ø–∏—Å—å–º–∞",\n'
                '    "body": "–î–æ–±—Ä—ã–π –¥–µ–Ω—å.\\n–ö–æ–ª–ª–µ–≥–∏, –∞–π–¥–æ–∫ –±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω.\\n\\nDemand Capture specialist\\nOrder to Cash\\nSBS Samara\\n\\nOrders@nestle.ru"\n'
                "  }\n"
                "}\n"
                "```\n"
                "–≠—Ç–æ—Ç –±–ª–æ–∫ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ —Å–∞–º–æ–º –∫–æ–Ω—Ü–µ –æ—Ç–≤–µ—Ç–∞."
            )

            system_content += (
                "=== –ö–û–ù–¢–ï–ö–°–¢ (–¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–∏–∂–µ) ===\n"
                f"{rag_db.last_glossary}"
                f"{context}"
            )

            # –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞
            response = requests.post(
                MODEL_API_URL,
                json={
                    "system_prompt": system_content,
                    "user_prompt": user_message,
                    "max_length": 1024,
                    "temperature": 0.15,
                    "top_p": 0.15,
                },
                timeout=60,
                proxies={"http": None, "https": None},
            )
            response.raise_for_status()

            # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞
            model_response = response.json()["response"]

            # –ü–∞—Ä—Å–∏–Ω–≥ mailto –∏–∑ AI –æ—Ç–≤–µ—Ç–∞
            match = re.search(
                r"```json\s*(\{[\s\S]*?\})\s*```", model_response, re.IGNORECASE
            )
            if not match:
                match = re.search(r"```\s*(\{[\s\S]*?\})\s*```", model_response)
            if not match:
                mailto_matches = list(
                    re.finditer(r'\{[^}]*"mailto"[^}]*\{[^}]*\}[^}]*\}', model_response)
                )
                if mailto_matches:
                    potential_json = mailto_matches[-1].group(0)
                    try:
                        parsed_test = json.loads(potential_json)
                        if "mailto" in parsed_test:
                            match = type(
                                "obj",
                                (object,),
                                {
                                    "group": lambda x: (
                                        potential_json if x == 1 else potential_json
                                    )
                                },
                            )
                    except:
                        pass

            mailto_data = None
            if match:
                try:
                    parsed = json.loads(match.group(1), strict=False)
                    mailto_data = parsed.get("mailto")
                    print(mailto_data)
                    model_response = model_response.replace(match.group(0), "").strip()
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –¥–ª—è mailto: {e}")

            print(model_response)
            processed_response = process_sources(model_response, actual_docs, links_dict)

            return jsonify({
                "type": "message",
                "text": processed_response,
                "mailto": mailto_data
            })
        
        else:
            # ===== –û–ë–´–ß–ù–´–ô –†–ï–ñ–ò–ú (–Ω–µ –ø–∏—Å—å–º–æ) =====
            print(f"\nüí¨ –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω")
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            try:
                with open("links.json", "r", encoding="utf-8") as f:
                    links_dict = json.load(f)
            except (FileNotFoundError, json.JSONDecodeError):
                links_dict = {}
            
            actual_docs = [
                doc["metadata"].split("docs_Samara/")[1] for doc in relevant_docs
            ]
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            system_content += (
                "=== –ö–û–ù–¢–ï–ö–°–¢ (–¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–∏–∂–µ) ===\n"
                f"{rag_db.last_glossary}"
                f"{context}"
            )
            
            # –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ AI –º–æ–¥–µ–ª–∏
            response = requests.post(
                MODEL_API_URL,
                json={
                    "system_prompt": system_content,
                    "user_prompt": user_message,
                    "max_length": 1024,
                    "temperature": 0.15,
                    "top_p": 0.15,
                },
                timeout=60,
                proxies={"http": None, "https": None},
            )
            response.raise_for_status()
            
            # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞
            model_response = response.json()["response"]
            print(f"–û—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏ –ø–æ–ª—É—á–µ–Ω: {model_response[:100]}...")
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            processed_response = process_sources(model_response, actual_docs, links_dict)
            
            return jsonify({
                "type": "message",
                "text": processed_response
            })

    except requests.exceptions.RequestException as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ –º–æ–¥–µ–ª–∏: {e}")
        return jsonify({"error": "Model service unavailable"}), 503
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞: {e}")
        return jsonify({"error": "Internal server error"}), 500


@app.route("/stats", methods=["GET"])
def stats_page():
    return render_template("stats.html")


@app.route("/stats/data", methods=["GET"])
def stats_data():
    return jsonify(build_stats_payload())


@app.route("/stats.xlsx", methods=["GET"])
def stats_excel():
    db = get_db()

    sessions_df = pd.read_sql_query("SELECT * FROM sessions", db)
    messages_df = pd.read_sql_query("SELECT * FROM messages", db)

    now = datetime.now(tz=timezone(timedelta(hours=3)))
    agg_rows = []

    for label, delta in [
        ("day", timedelta(days=1)),
        ("week", timedelta(days=7)),
        ("month", timedelta(days=30)),
        ("all_time", None),
    ]:
        if delta:
            dt_from = now - delta
        else:
            dt_from = datetime(1970, 1, 1, tzinfo=now.tzinfo)

        req_cnt = db.execute(
            "SELECT COUNT(*) FROM messages WHERE timestamp >= ?", (dt_from,)
        ).fetchone()[0]

        sess_cnt = db.execute(
            "SELECT COUNT(*) FROM sessions WHERE start_time >= ?", (dt_from,)
        ).fetchone()[0]

        agg_rows.append({"period": label, "requests": req_cnt, "sessions": sess_cnt})

    agg_df = pd.DataFrame(agg_rows)
    mps_df = pd.read_sql_query(
        """
        SELECT s.session_id, COUNT(m.id) AS messages_count
        FROM sessions s
        LEFT JOIN messages m ON s.session_id = m.session_id
        GROUP BY s.session_id
        """,
        db,
    )

    percent_df = pd.DataFrame(
        [{"percent_sessions_with_messages": percent_sessions_with_messages()}]
    )

    output = io.BytesIO()
    with pd.ExcelWriter(output, engine="openpyxl") as writer:
        agg_df.to_excel(writer, sheet_name="aggregates", index=False)
        sessions_df.to_excel(writer, sheet_name="sessions", index=False)
        messages_df.to_excel(writer, sheet_name="messages", index=False)
        mps_df.to_excel(writer, sheet_name="messages_per_session", index=False)
        percent_df.to_excel(writer, sheet_name="percent", index=False)

    output.seek(0)

    return send_file(
        output,
        as_attachment=True,
        download_name="stats.xlsx",
        mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )


def process_sources(response_text, actual_docs, links_dict):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏: –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç —Å—Å—ã–ª–∫–∏.
    –ï—Å–ª–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –Ω–µ—Ç –∏–ª–∏ –æ–Ω–∏ –≤—ã–º—ã—à–ª–µ–Ω—ã ‚Äî —Å—Ç–∞–≤–∏—Ç 0/10 –∏ —É–¥–∞–ª—è–µ—Ç [1], [2] –∏ —Ç.–¥.
    """
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–∞–∑–¥–µ–ª "–ò—Å—Ç–æ—á–Ω–∏–∫–∏"
    sources_match = re.search(
        r"<h3>–ò—Å—Ç–æ—á–Ω–∏–∫–∏</h3>\s*<ol>(.*?)</ol>", response_text, re.DOTALL
    )

    if not sources_match:
        # –ù–µ—Ç —Ä–∞–∑–¥–µ–ª–∞ "–ò—Å—Ç–æ—á–Ω–∏–∫–∏" ‚Äî —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ –∏—Ö –Ω–µ—Ç
        response_text = re.sub(r"\[\d+\]", "", response_text)
        response_text = re.sub(
            r"–¢–æ—á–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞:<b> \d+/10</b>",
            "–¢–æ—á–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞:<b> 0/10</b>",
            response_text,
        )
        new_sources_section = (
            '<h3>–ò—Å—Ç–æ—á–Ω–∏–∫–∏</h3>\n<p style="color: red;">–ù–µ –Ω–∞–π–¥–µ–Ω–æ!</p>'
        )
        response_text = re.sub(
            r"<h3>–ò—Å—Ç–æ—á–Ω–∏–∫–∏</h3>\s*<ol>.*?</ol>",
            new_sources_section,
            response_text,
            flags=re.DOTALL,
        )
        return response_text

    sources_content = sources_match.group(1)
    source_items = re.findall(r"<li>(.*?)</li>", sources_content, re.DOTALL)

    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ, —á—Ç–æ –µ—Å—Ç—å –≤ links_dict
    valid_sources = []
    print(source_items)
    for item in source_items:
        clean_item = re.sub(r"<[^>]+>", "", item).strip()
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ä–µ–∞–ª—å–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç —á–∞—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞
        matched = False
        for path in actual_docs:
            if (
                path in clean_item
                or clean_item in path
                or clean_item == path.split("/")[-1]
            ):
                if path in links_dict:
                    valid_sources.append((item, links_dict[path]))
                    matched = True
                    break
        if not matched:
            valid_sources.append((item, None))

    # –ï—Å–ª–∏ –Ω–∏ –æ–¥–∏–Ω –∏—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ –≤–∞–ª–∏–¥–Ω—ã–π
    if not any(link is not None for _, link in valid_sources):
        response_text = re.sub(r"\[\d+\]", "", response_text)
        response_text = re.sub(
            r"–¢–æ—á–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞:<b> \d+/10</b>",
            "–¢–æ—á–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞:<b> 0/10</b>",
            response_text,
        )
        new_sources_section = (
            '<h3>–ò—Å—Ç–æ—á–Ω–∏–∫–∏</h3>\n<p style="color: red;">–ù–µ –Ω–∞–π–¥–µ–Ω–æ!</p>'
        )
    else:
        # –ï—Å—Ç—å –≤–∞–ª–∏–¥–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ ‚Äî –æ–±–æ—Ä–∞—á–∏–≤–∞–µ–º –∏—Ö –≤ —Å—Å—ã–ª–∫–∏
        new_list_items = []
        for item, link in valid_sources:
            if link is not None:
                new_list_items.append(
                    f'<li><a href="{link}" target="_blank">{item}</a></li>'
                )
            else:
                new_list_items.append(f"<li>{item}</li>")
        new_sources_section = f"<h3>–ò—Å—Ç–æ—á–Ω–∏–∫–∏</h3><ol>{''.join(new_list_items)}</ol>"

    # –ó–∞–º–µ–Ω—è–µ–º –≤–µ—Å—å –±–ª–æ–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    response_text = re.sub(
        r"<h3>–ò—Å—Ç–æ—á–Ω–∏–∫–∏</h3>\s*<ol>.*?</ol>",
        new_sources_section,
        response_text,
        flags=re.DOTALL,
    )

    return response_text


if __name__ == "__main__":
    rag_db = RAGDatabase()
    try:
        rag_db.load_index()
    except Exception as e:
        print(f"[!] –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–Ω–¥–µ–∫—Å–∞: {e}")
        # print("[*] –°—Ç—Ä–æ–∏–º –Ω–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å...")
        # rag_db.build_index()

    app.run(host="localhost", port=5000, debug=True, use_reloader=False)
